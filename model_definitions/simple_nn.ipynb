{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class VolatilityModel(nn.Module):\n",
    "    def __init__(self, num_stocks, feature_dim):\n",
    "        super().__init__()\n",
    "        self.num_stocks = num_stocks\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        self.stock_embedding = nn.Embedding(self.num_stocks, 8)\n",
    "        self.gru = nn.GRU(feature_dim=self.feature_dim, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        \n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(64 + 8, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2757cc8fc44d60b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# (seq_len, features_dim) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c730e36b34b50c2d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims: list, output_dim: int, dropout=0.10):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        \n",
    "        fan_in = self.input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            self.hidden_layers.append(nn.Linear(fan_in, hidden_dim))\n",
    "            fan_in = hidden_dim\n",
    "        self.hidden_layers.append(nn.Linear(fan_in, self.output_dim))\n",
    "        \n",
    "        self.gelu = nn.GELU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    @staticmethod\n",
    "    def criterion(pred, y):\n",
    "        loss = torch.mean((1 - (pred / y))**2)\n",
    "        return loss\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.hidden_layers[:-1]:\n",
    "            x = layer(x)\n",
    "            x = self.gelu(x)\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.hidden_layers[-1](x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40882e0328018e75",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_csv('../baseline2.csv', index_col=False).iloc[:, 1:]\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b21da86082ab97ec",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ee535b375fa2c8e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = df.drop(columns=['stock_id', 'time_id', 'target'])\n",
    "y = df['target']\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "X = torch.tensor(X).to(torch.float)\n",
    "y = torch.tensor(y).to(torch.float) * 10000"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee419809ba95f59b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bf5863fb6313a67",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5f2f7149ccfa329",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "INPUT_DIM = X_train.shape[1]\n",
    "OUTPUT_DIM = 1\n",
    "HIDDEN_DIMS = [256, 256, 256]\n",
    "DROPOUT_RATE = 0.1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "215e8aae90692ba6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3f73ca11534b1c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "criterion = SimpleMLP.criterion\n",
    "model = SimpleMLP(INPUT_DIM, HIDDEN_DIMS, OUTPUT_DIM, DROPOUT_RATE)\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "num_epochs = 100\n",
    "device = 'cuda'\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for i, (batch_x, batch_y) in enumerate(dataloader):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(batch_x)\n",
    "        loss = criterion(preds, batch_y)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}, Loss: {epoch_loss / len(dataloader)}.')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed57f8b6a185761",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
